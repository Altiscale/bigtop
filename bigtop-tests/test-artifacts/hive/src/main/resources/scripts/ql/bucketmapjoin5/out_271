USE  TEST_HIVE_NORMAL


CREATE TABLE srcbucket_mapjoin(key int, value string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE

load data local inpath 'seed_data_files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin

load data local inpath 'seed_data_files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin


CREATE TABLE srcbucket_mapjoin_part (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 4 BUCKETS STORED AS TEXTFILE

load data local inpath 'seed_data_files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')

load data local inpath 'seed_data_files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-08')

load data local inpath 'seed_data_files/srcbucket20.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')

load data local inpath 'seed_data_files/srcbucket21.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part partition(ds='2008-04-09')


CREATE TABLE srcbucket_mapjoin_part_2 (key int, value string) partitioned by (ds string) CLUSTERED BY (key) INTO 2 BUCKETS STORED AS TEXTFILE

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-08')

load data local inpath 'seed_data_files/srcbucket22.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-09')

load data local inpath 'seed_data_files/srcbucket23.txt' INTO TABLE srcbucket_mapjoin_part_2 partition(ds='2008-04-09')


create table bucketmapjoin_hash_result_1 (key bigint , value1 bigint, value2 bigint)

create table bucketmapjoin_hash_result_2 (key bigint , value1 bigint, value2 bigint)
set hive.optimize.bucketmapjoin = true

create table bucketmapjoin_tmp_result (key string , value1 string, value2 string)


explain extended
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
on a.key=b.key
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_JOIN
         TOK_TABREF
            TOK_TABNAME
               srcbucket_mapjoin
            a
         TOK_TABREF
            TOK_TABNAME
               srcbucket_mapjoin_part
            b
         =
            .
               TOK_TABLE_OR_COL
                  a
               key
            .
               TOK_TABLE_OR_COL
                  b
               key
   TOK_INSERT
      TOK_DESTINATION
         TOK_TAB
            TOK_TABNAME
               bucketmapjoin_tmp_result
      TOK_SELECT
         TOK_HINTLIST
            TOK_HINT
               TOK_MAPJOIN
               TOK_HINTARGLIST
                  a
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               value
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               value


STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce Local Work
      Alias -> Map Local Tables:
        a 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        a 
          TableScan
            alias: a
            Statistics: Num rows: 26 Data size: 2750 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 13 Data size: 1375 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 key (type: int)
                  1 key (type: int)
                Position of Big Table: 1

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: b
            Statistics: Num rows: 110 Data size: 11624 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 55 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col1, _col6
                Position of Big Table: 1
                Statistics: Num rows: 60 Data size: 6393 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: string), _col6 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 60 Data size: 6393 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/.hive-staging_hive_2015-09-26_20-54-54_332_4338287893183438533-1/-ext-10000
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 60 Data size: 6393 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/.hive-staging_hive_2015-09-26_20-54-54_332_4338287893183438533-1/-ext-10000/
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          bucket_count -1
                          columns key,value1,value2
                          columns.comments 
                          columns.types string:string:string
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result
                          name test_hive_normal.bucketmapjoin_tmp_result
                          serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          transient_lastDdlTime 1443300894
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: test_hive_normal.bucketmapjoin_tmp_result
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false
      Local Work:
        Map Reduce Local Work
      Path -> Alias:
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-08 [b]
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-09 [b]
      Path -> Partition:
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin 
          Partition
            base file name: srcbucket_mapjoin
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.comments 
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin
              name test_hive_normal.srcbucket_mapjoin
              numFiles 2
              serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2750
              transient_lastDdlTime 1443300887
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.comments 
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin
                name test_hive_normal.srcbucket_mapjoin
                numFiles 2
                serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 2750
                transient_lastDdlTime 1443300887
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.srcbucket_mapjoin
            name: test_hive_normal.srcbucket_mapjoin
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-08 
          Partition
            base file name: ds=2008-04-08
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count 4
              bucket_field_name key
              columns key,value
              columns.comments 
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-08
              name test_hive_normal.srcbucket_mapjoin_part
              numFiles 4
              numRows -1
              partition_columns ds
              partition_columns.types string
              rawDataSize -1
              serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
              transient_lastDdlTime 1443300889
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name key
                columns key,value
                columns.comments 
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part
                name test_hive_normal.srcbucket_mapjoin_part
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1443300887
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.srcbucket_mapjoin_part
            name: test_hive_normal.srcbucket_mapjoin_part
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-09 
          Partition
            base file name: ds=2008-04-09
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count 4
              bucket_field_name key
              columns key,value
              columns.comments 
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-09
              name test_hive_normal.srcbucket_mapjoin_part
              numFiles 4
              numRows -1
              partition_columns ds
              partition_columns.types string
              rawDataSize -1
              serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
              transient_lastDdlTime 1443300891
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 4
                bucket_field_name key
                columns key,value
                columns.comments 
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part
                name test_hive_normal.srcbucket_mapjoin_part
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct srcbucket_mapjoin_part { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1443300887
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.srcbucket_mapjoin_part
            name: test_hive_normal.srcbucket_mapjoin_part
      Truncated Path -> Alias:
        /test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-08 [b]
        /test_hive_normal.db/srcbucket_mapjoin_part/ds=2008-04-09 [b]

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/.hive-staging_hive_2015-09-26_20-54-54_332_4338287893183438533-1/-ext-10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value1,value2
                columns.comments 
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result
                name test_hive_normal.bucketmapjoin_tmp_result
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1443300894
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.bucketmapjoin_tmp_result



insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
on a.key=b.key


select count(1) from bucketmapjoin_tmp_result
928

insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
set hive.optimize.bucketmapjoin = false

insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part b 
on a.key=b.key
Moved: 'hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/000000_0' to trash at: hdfs://HADOOP/user/USER/.Trash/Current


select count(1) from bucketmapjoin_tmp_result
928

insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result


select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
0	0	0
set hive.optimize.bucketmapjoin = true

explain extended
insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part_2 b 
on a.key=b.key
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_JOIN
         TOK_TABREF
            TOK_TABNAME
               srcbucket_mapjoin
            a
         TOK_TABREF
            TOK_TABNAME
               srcbucket_mapjoin_part_2
            b
         =
            .
               TOK_TABLE_OR_COL
                  a
               key
            .
               TOK_TABLE_OR_COL
                  b
               key
   TOK_INSERT
      TOK_DESTINATION
         TOK_TAB
            TOK_TABNAME
               bucketmapjoin_tmp_result
      TOK_SELECT
         TOK_HINTLIST
            TOK_HINT
               TOK_MAPJOIN
               TOK_HINTARGLIST
                  a
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               key
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  a
               value
         TOK_SELEXPR
            .
               TOK_TABLE_OR_COL
                  b
               value


STAGE DEPENDENCIES:
  Stage-4 is a root stage
  Stage-3 depends on stages: Stage-4
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-4
    Map Reduce Local Work
      Alias -> Map Local Tables:
        a 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        a 
          TableScan
            alias: a
            Statistics: Num rows: 26 Data size: 2750 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 13 Data size: 1375 Basic stats: COMPLETE Column stats: NONE
              HashTable Sink Operator
                keys:
                  0 key (type: int)
                  1 key (type: int)
                Position of Big Table: 1

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: b
            Statistics: Num rows: 58 Data size: 6124 Basic stats: COMPLETE Column stats: NONE
            GatherStats: false
            Filter Operator
              isSamplingPred: false
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 29 Data size: 3062 Basic stats: COMPLETE Column stats: NONE
              Map Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 key (type: int)
                  1 key (type: int)
                outputColumnNames: _col0, _col1, _col6
                Position of Big Table: 1
                Statistics: Num rows: 31 Data size: 3368 Basic stats: COMPLETE Column stats: NONE
                Select Operator
                  expressions: _col0 (type: int), _col1 (type: string), _col6 (type: string)
                  outputColumnNames: _col0, _col1, _col2
                  Statistics: Num rows: 31 Data size: 3368 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    GlobalTableId: 1
                    directory: hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/.hive-staging_hive_2015-09-26_20-57-57_467_6754182710199705257-1/-ext-10000
                    NumFilesPerFileSink: 1
                    Statistics: Num rows: 31 Data size: 3368 Basic stats: COMPLETE Column stats: NONE
                    Stats Publishing Key Prefix: hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/.hive-staging_hive_2015-09-26_20-57-57_467_6754182710199705257-1/-ext-10000/
                    table:
                        input format: org.apache.hadoop.mapred.TextInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        properties:
                          COLUMN_STATS_ACCURATE false
                          bucket_count -1
                          columns key,value1,value2
                          columns.comments 
                          columns.types string:string:string
                          file.inputformat org.apache.hadoop.mapred.TextInputFormat
                          file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                          location hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result
                          name test_hive_normal.bucketmapjoin_tmp_result
                          numFiles 1
                          numRows -1
                          rawDataSize -1
                          serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                          serialization.format 1
                          serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                          totalSize 17966
                          transient_lastDdlTime 1443300998
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        name: test_hive_normal.bucketmapjoin_tmp_result
                    TotalFiles: 1
                    GatherStats: false
                    MultiFileSpray: false
      Local Work:
        Map Reduce Local Work
      Path -> Alias:
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]
      Path -> Partition:
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin 
          Partition
            base file name: srcbucket_mapjoin
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.comments 
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin
              name test_hive_normal.srcbucket_mapjoin
              numFiles 2
              serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 2750
              transient_lastDdlTime 1443300887
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.comments 
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin
                name test_hive_normal.srcbucket_mapjoin
                numFiles 2
                serialization.ddl struct srcbucket_mapjoin { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 2750
                transient_lastDdlTime 1443300887
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.srcbucket_mapjoin
            name: test_hive_normal.srcbucket_mapjoin
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-08 
          Partition
            base file name: ds=2008-04-08
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-08
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.comments 
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-08
              name test_hive_normal.srcbucket_mapjoin_part_2
              numFiles 2
              numRows -1
              partition_columns ds
              partition_columns.types string
              rawDataSize -1
              serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 3062
              transient_lastDdlTime 1443300892
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.comments 
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2
                name test_hive_normal.srcbucket_mapjoin_part_2
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1443300891
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.srcbucket_mapjoin_part_2
            name: test_hive_normal.srcbucket_mapjoin_part_2
        hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-09 
          Partition
            base file name: ds=2008-04-09
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            partition values:
              ds 2008-04-09
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count 2
              bucket_field_name key
              columns key,value
              columns.comments 
              columns.types int:string
              file.inputformat org.apache.hadoop.mapred.TextInputFormat
              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-09
              name test_hive_normal.srcbucket_mapjoin_part_2
              numFiles 2
              numRows -1
              partition_columns ds
              partition_columns.types string
              rawDataSize -1
              serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 3062
              transient_lastDdlTime 1443300893
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count 2
                bucket_field_name key
                columns key,value
                columns.comments 
                columns.types int:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/srcbucket_mapjoin_part_2
                name test_hive_normal.srcbucket_mapjoin_part_2
                partition_columns ds
                partition_columns.types string
                serialization.ddl struct srcbucket_mapjoin_part_2 { i32 key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                transient_lastDdlTime 1443300891
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.srcbucket_mapjoin_part_2
            name: test_hive_normal.srcbucket_mapjoin_part_2
      Truncated Path -> Alias:
        /test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-08 [b]
        /test_hive_normal.db/srcbucket_mapjoin_part_2/ds=2008-04-09 [b]

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/.hive-staging_hive_2015-09-26_20-57-57_467_6754182710199705257-1/-ext-10000
          table:
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                COLUMN_STATS_ACCURATE false
                bucket_count -1
                columns key,value1,value2
                columns.comments 
                columns.types string:string:string
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result
                name test_hive_normal.bucketmapjoin_tmp_result
                numFiles 1
                numRows -1
                rawDataSize -1
                serialization.ddl struct bucketmapjoin_tmp_result { string key, string value1, string value2}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 17966
                transient_lastDdlTime 1443300998
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: test_hive_normal.bucketmapjoin_tmp_result



insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part_2 b 
on a.key=b.key
Moved: 'hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/000000_0' to trash at: hdfs://HADOOP/user/USER/.Trash/Current


select count(1) from bucketmapjoin_tmp_result
0

insert overwrite table bucketmapjoin_hash_result_1
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
Moved: 'hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_hash_result_1/000000_0' to trash at: hdfs://HADOOP/user/USER/.Trash/Current
set hive.optimize.bucketmapjoin = false

insert overwrite table bucketmapjoin_tmp_result 
select /*+mapjoin(a)*/ a.key, a.value, b.value 
from srcbucket_mapjoin a join srcbucket_mapjoin_part_2 b 
on a.key=b.key
Moved: 'hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_tmp_result/000000_0' to trash at: hdfs://HADOOP/user/USER/.Trash/Current


select count(1) from bucketmapjoin_tmp_result
0

insert overwrite table bucketmapjoin_hash_result_2
select sum(hash(key)), sum(hash(value1)), sum(hash(value2)) from bucketmapjoin_tmp_result
Moved: 'hdfs://HADOOP/hive/test_hive_normal.db/bucketmapjoin_hash_result_2/000000_0' to trash at: hdfs://HADOOP/user/USER/.Trash/Current


select a.key-b.key, a.value1-b.value1, a.value2-b.value2
from bucketmapjoin_hash_result_1 a left outer join bucketmapjoin_hash_result_2 b
on a.key = b.key
NULL	NULL	NULL
